---
layout: post
title:  "Web 3.0"
author: Comandeer
date: 2023-12-29T19:11:00+0100
categories: refleksje standardy-sieciowe
comments: true
permalink: /web-3.0.html
---

Z Web 3.0 jest jak z końcem świata – przeżyłem ich już kilka. Obecna wersja (zapisywana jako "Web3") ma odmienić oblicze Sieci przy pomocy [mieszanki blockchaina i AI](https://adactio.com/articles/20290), ale [średnio to na razie wychodzi](https://web3isgoinggreat.com/). Dlatego nie o tym Web 3.0 będzie dzisiaj.

Paradoksalnie najtrwalszym pomysłem na nową wersję Sieci była pierwotna wizja, która powstała lata temu i w którą swego czasu bardzo mocno zaangażowało się W3C. Pomysł był żywy już w 2007 roku, gdy [Steve Bratt prezentował go na forum tego ciała standaryzacyjnego](https://www.w3.org/2007/Talks/0123-sb-W3CEmergingTech/Overviewp.pdf). W tej prezentacji pada także definicja tego, jak wyobrażano sobie wówczas nową Sieć (slajd 3):

> <span lang="en" dir="ltr">Web of Data and Services</span>
>
> \[Sieć danych i usług\]

Bardzo podoba mi się spójność całej wizji roztaczanej przez Bratta. Pokazuje on, w jaki sposób dzięki otwartym standardom sieciowym udało się stworzyć podwaliny Sieci dostępnej dla wszystkich i jak ekspansja na różne urządzenia, w tym mobilne, będzie kolejnym krokiem w ewolucji Sieci. Dzisiaj, _16 lat później_, wiemy już, że tak faktycznie było. Niemniej w ówczesnej wizji W3C po Sieci dostępnej dla wszystkich i na każdym urządzeniu miał nastąpić ostatni etap – Web 3.0, Sieć danych i usług. Miała to być Sieć, która byłaby zrozumiała zarówno dla ludzi, jak i dla maszyn. A to miało pozwalać na oferowanie wielu ciekawych usług, typu automatyczne wyszukiwanie ceny biletów i zamawianie ich, wyciąganie ze strony pobliskich restauracji menu, itd. Web 3.0 to miała być Sieć współpracująca z użytkownikami w celu jak najszybszego spełnienia ich celów.

Urzeczywistnić tę wizję miały nowe standardy sieciowe, wprowadzające technologie do opisywania danych w sposób umożliwiający ich maszynowe przetwarzanie. I takie technologie [faktycznie powstały](https://www.smashingmagazine.com/2020/10/developing-semantic-web/)! Wśród nich warto wymienić trzy:

*   [RDF](https://developer.mozilla.org/en-US/docs/Glossary/RDF)/[RDFa](https://en.wikipedia.org/wiki/RDFa),
*   [JSON-LD](https://json-ld.org/),
*   [mikrodata](https://developer.mozilla.org/en-US/docs/Web/HTML/Microdata). 

Dzięki nim można dokładnie opisywać poszczególne fragmenty treści, np. informując, że fragment "25 złotych" to cena produktu. Takie informacje są następnie wykorzystywane m.in. [przez wyszukiwarki internetowe do tego, by prezentować dokładniejsze wyniki wyszukiwania](https://developers.google.com/search/blog/2019/04/enriching-search-results-structured-data), czy [przez przeglądarki do lepszego prezentowania treści](https://twitter.com/rmondello/status/1109850097183911937). Dodatkowo wyszukiwarki internetowe (w tym Google i Bing) zgodziły się na [wspólny format opisywania treści, Schema.org](https://schema.org/).

Można by więc rzec, że wizja W3C urzeczywistniła się. I tak faktycznie się stało… ale do pewnego stopnia. Już w 2001 roku pojawiały się głosy, że [wizja w pełni semantycznej Sieci jest utopijna](https://people.well.com/user/doctorow/metacrap.htm). Dzisiaj można przyznać im rację. Web 3.0 zostało wdrożone tylko w małym kawałku, głównie w wyszukiwarkach. Dodatkowo stosunkowo mało autorów stron używa technologii do opisu treści, przez co nie są one tak użyteczne, jak mogłyby być. Nie ma też jednego formatu do opisu danych. Owszem, jest Schema.org, ale znów – to inicjatywa głównie wyszukiwarek. Jeśli mówimy o innych narzędziach, to często zmuszone są one do ręcznego pobierania i parsowania treści różnych stron internetowych. Dodajmy do tego zamknięte silosy danych (takie jak wielkie sieci społecznościowe) i nagle okazuje się, że z Web 3.0 został smutny cień.

Chociaż być może prawdziwą przyszłością semantycznej Sieci zrozumiałej zarówno dla ludzi, jak i maszyn, wcale nie będą technologie do dodatkowego oznaczania treści. Jesteśmy w samym środku wielkiej rewolucji związanej ze sztuczną inteligencją, a dokładniej – wielkimi modelami językowymi (LLM). Ta technologia jest [dobra w rozumieniu języka naturalnego](https://shkspr.mobi/blog/2023/05/does-ai-mean-we-dont-need-the-semantic-web/). Być może zatem rozwój LLM sprawi, że praktycznie każda strona stanie się częścią Web 3.0. Zapewne byłby to ciekawy obrót sytuacji.
